{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". You can run all the tests with the validate button. If the validate command takes too long, you can also confirm that you pass all the tests if you can run through the whole notebook without getting validation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cfed4145e7691bea90d677778341b82",
     "grade": false,
     "grade_id": "cell-17b7f781a24a8028",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For this problem set, we'll be using the Jupyter notebook:\n",
    "\n",
    "![](jupyter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe05ed4052fd9ac5999bebf7fb531833",
     "grade": false,
     "grade_id": "cell-374465d0c2cecffb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Music recommender exercises\n",
    "\n",
    "In this notebook you will make recommendations based on user's music preferences. Training is done with alternating least squares (ALS) recommendation model to recommend songs to users.\n",
    "\n",
    "https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html#collaborative-filtering\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/_modules/pyspark/mllib/recommendation.html\n",
    "\n",
    "dataset by:  \n",
    "Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere.   \n",
    "The Million Song Dataset. In Proceedings of the 12th International Society  \n",
    "for Music Information Retrieval Conference (ISMIR 2011), 2011.  \n",
    "\n",
    "We use a sample data of \"uniqe_tracks.txt\" from http://millionsongdataset.com/sites/default/files/AdditionalFiles/unique_tracks.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82d170ae68f823fa784a88141af2b228",
     "grade": false,
     "grade_id": "cell-7b32d782903bb5ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.mllib\n",
    "from pyspark.sql import *\n",
    "from pyspark import *\n",
    "from pyspark.rdd import *\n",
    "from pyspark.ml import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "\n",
    "\n",
    "sc = SparkContext(\"local\",\"music\")\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "sampleUsersPath = \"sampleUsers.txt\"\n",
    "sampleTracksPath = \"sampleTracks.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf0347f30ab1bb7f3c66911cf16011ac",
     "grade": false,
     "grade_id": "cell-a3c50156d72dc064",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Load\n",
    "\n",
    "Load data from path and create a dataframe from it. It should have three (3) columns:  \n",
    "-> `user`: String (user_id)  \n",
    "-> `song`: String (song_id)  \n",
    "-> `count`: Int (number of times listened)  \n",
    "\n",
    "Columns are seperated by \"\\t\".  \n",
    "Counts that are higher than 20 should be reduced to 20.  \n",
    "Using the `StructField`schema can help.\n",
    "\n",
    "param `path` path to file (users.txt)  \n",
    "`return` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80be363608e783f6901baf82973be3a2",
     "grade": false,
     "grade_id": "cell-d4d65f391b2e8dc9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    schema = StructType([\n",
    "                        StructField(\"user\", StringType()), \n",
    "                        StructField(\"song\", StringType()),\n",
    "                        StructField(\"count\", IntegerType())\n",
    "    ])\n",
    "    df = spark.read.text(path)\n",
    "    rddFromDF = df.rdd.map(lambda row: row.value.split('\\t'))\n",
    "    rddFromDF = rddFromDF.map(lambda row: [row[0], row[1], int(row[2]) if int(row[2]) <= 20 else 20])\n",
    "    dff = spark.createDataFrame(rddFromDF, schema)\n",
    "    return dff\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fca23fc22c72e401b0c11a1417334e41",
     "grade": false,
     "grade_id": "cell-5811b93da6bc198e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+\n",
      "|                user|              song|count|\n",
      "+--------------------+------------------+-----+\n",
      "|b80344d063b5ccb32...|SOBBMDR12A8C13253B|    2|\n",
      "|b80344d063b5ccb32...|SODZWFT12A8C13C0E4|    1|\n",
      "|b80344d063b5ccb32...|SOHQWYZ12A6D4FA701|    1|\n",
      "|b80344d063b5ccb32...|SOJNNUA12A8AE48C7A|    1|\n",
      "|b80344d063b5ccb32...|SOLXHAI12A6D4FD6F3|    1|\n",
      "|b80344d063b5ccb32...|SOOSIVQ12A6D4F8AE0|    1|\n",
      "|b80344d063b5ccb32...|SORJNVW12A8C13BF90|    1|\n",
      "|85c1f87fea955d09b...|SODJTHN12AF72A8FCD|    2|\n",
      "|85c1f87fea955d09b...|SOIDFHN12A8C13ABAC|    2|\n",
      "|4bd88bfb25263a75b...|SOWEHOM12A6BD4E09E|    1|\n",
      "|9d6f0ead607ac2a6c...|SOCLQES12A58A7BB1D|    2|\n",
      "|9d6f0ead607ac2a6c...|SOKLRPJ12A8C13C3FE|    2|\n",
      "|9bb911319fbc04f01...|SOXBXBI12A8C13C71C|    5|\n",
      "|b64cdd1a0bd907e5e...|SOBDWET12A6701F114|    2|\n",
      "|b64cdd1a0bd907e5e...|SOLQYOG12B0B80BA71|    2|\n",
      "|b64cdd1a0bd907e5e...|SOZPQES12A6D4F8E57|    2|\n",
      "|17aa9f6dbdf753831...|SODHHEG12A58A779FB|    2|\n",
      "|17aa9f6dbdf753831...|SODUANR12A6D4F5036|    1|\n",
      "|17aa9f6dbdf753831...|SOJPFPR12AB018109D|    1|\n",
      "|17aa9f6dbdf753831...|SOJUVYA12AB01860BA|    2|\n",
      "+--------------------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded = load(sampleUsersPath).persist()\n",
    "loaded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59f9d8933c86e00669bfd9b4775f79b5",
     "grade": true,
     "grade_id": "cell-f8d75cb13579da04",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''load test'''\n",
    "correctCols = StructType([\\\n",
    "StructField(\"user\",StringType(),True),\\\n",
    "StructField(\"song\",StringType(),True),\\\n",
    "StructField(\"count\",IntegerType(),True)])\n",
    "\n",
    "fakeData = [(\"abc123\", \"123abc\", 2)]\n",
    "\n",
    "fakeDf = spark.createDataFrame(fakeData, correctCols)\n",
    "\n",
    "assert loaded.dtypes == fakeDf.dtypes, \"the schema was expected to be %s but it was %s\" % (fakeDf.dtypes, loaded.dtypes)\n",
    "\n",
    "assert loaded.filter('count>20').count() == 0, \"counts higher than 20 was expected to be 0 but it was %s\" % loaded.filter('count>20').count()\n",
    "\n",
    "test1 = str(loaded.sample(False, 0.01, seed=123).limit(1).first())\n",
    "correct1 = \"Row(user='a58de017cbeda1763ea002fe027ed41b4ed53109', song='SOJTLHS12A8C13F633', count=3)\"\n",
    "assert test1 == correct1, \"the row was expected to be %s but it was %s\" % (correct1, test1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3aa4c3bbc3829d2bf48a6cb9254f8f1",
     "grade": false,
     "grade_id": "cell-b3d2c6d16ab64fd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Convert\n",
    "\n",
    "Convert user and song fields into doubles. Use mllib's StringIndexer. Final schema:  \n",
    "-> `user`: String  \n",
    "-> `song`: String  \n",
    "-> `count`: Int  \n",
    "-> `user_indexed`: Double  \n",
    "-> `song_indexed`: Double  \n",
    "\n",
    "param `df` Dataframe which has been created using method `load()`  \n",
    "`return` Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b7c80244cfbd74f66d21561930c655",
     "grade": false,
     "grade_id": "cell-8c985920cfb45fb1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convert(df):\n",
    "    inputc = [\"user\", \"song\"]\n",
    "    outputc = [\"user_indexed\", \"song_indexed\"]\n",
    "    stringIndexer = StringIndexer(inputCols=inputc, outputCols=outputc)\n",
    "    model = stringIndexer.fit(df)\n",
    "    result = model.transform(df)\n",
    "    return result\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b36cf5d1fbf8b9a46c1eb2fe0a17466",
     "grade": false,
     "grade_id": "cell-d819affce2d87b87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------------+------------+\n",
      "|                user|              song|count|user_indexed|song_indexed|\n",
      "+--------------------+------------------+-----+------------+------------+\n",
      "|b80344d063b5ccb32...|SOBBMDR12A8C13253B|    2|       162.0|       577.0|\n",
      "|b80344d063b5ccb32...|SODZWFT12A8C13C0E4|    1|       162.0|      1053.0|\n",
      "|b80344d063b5ccb32...|SOHQWYZ12A6D4FA701|    1|       162.0|      1646.0|\n",
      "|b80344d063b5ccb32...|SOJNNUA12A8AE48C7A|    1|       162.0|      1945.0|\n",
      "|b80344d063b5ccb32...|SOLXHAI12A6D4FD6F3|    1|       162.0|      2306.0|\n",
      "|b80344d063b5ccb32...|SOOSIVQ12A6D4F8AE0|    1|       162.0|      2702.0|\n",
      "|b80344d063b5ccb32...|SORJNVW12A8C13BF90|    1|       162.0|      3124.0|\n",
      "|85c1f87fea955d09b...|SODJTHN12AF72A8FCD|    2|       810.0|       951.0|\n",
      "|85c1f87fea955d09b...|SOIDFHN12A8C13ABAC|    2|       810.0|      1728.0|\n",
      "|4bd88bfb25263a75b...|SOWEHOM12A6BD4E09E|    1|      1151.0|      3824.0|\n",
      "|9d6f0ead607ac2a6c...|SOCLQES12A58A7BB1D|    2|       839.0|       803.0|\n",
      "|9d6f0ead607ac2a6c...|SOKLRPJ12A8C13C3FE|    2|       839.0|         5.0|\n",
      "|9bb911319fbc04f01...|SOXBXBI12A8C13C71C|    5|      1317.0|      3948.0|\n",
      "|b64cdd1a0bd907e5e...|SOBDWET12A6701F114|    2|       560.0|       586.0|\n",
      "|b64cdd1a0bd907e5e...|SOLQYOG12B0B80BA71|    2|       560.0|       245.0|\n",
      "|b64cdd1a0bd907e5e...|SOZPQES12A6D4F8E57|    2|       560.0|      4289.0|\n",
      "|17aa9f6dbdf753831...|SODHHEG12A58A779FB|    2|       115.0|       934.0|\n",
      "|17aa9f6dbdf753831...|SODUANR12A6D4F5036|    1|       115.0|      1013.0|\n",
      "|17aa9f6dbdf753831...|SOJPFPR12AB018109D|    1|       115.0|      1958.0|\n",
      "|17aa9f6dbdf753831...|SOJUVYA12AB01860BA|    2|       115.0|      1988.0|\n",
      "+--------------------+------------------+-----+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converted = convert(loaded).persist()\n",
    "converted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f96d4421e34d23ed179c414dddf5249f",
     "grade": true,
     "grade_id": "cell-cc23b073c7d40012",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''convert test'''\n",
    "correctCols = StructType([\\\n",
    "StructField(\"user\",StringType(),True),\\\n",
    "StructField(\"song\",StringType(),True),\\\n",
    "StructField(\"count\",IntegerType(),True),\\\n",
    "StructField(\"user_indexed\",DoubleType(),True),\\\n",
    "StructField(\"song_indexed\",DoubleType(),True)])\n",
    "\n",
    "fakeData = [(\"abc123\", \"123abc\", 2, 1.0, 2.0)]\n",
    "\n",
    "fakeDf = spark.createDataFrame(fakeData, correctCols)\n",
    "\n",
    "assert converted.dtypes == fakeDf.dtypes, \"the schema was expected to be %s but it was %s\" % (fakeDf.dtypes, converted.dtypes)\n",
    "\n",
    "test2 = str(converted.sample(False, 0.1, seed=1234).limit(1).first())\n",
    "correct2 = \"Row(user='5a905f000fc1ff3df7ca807d57edb608863db05d', song='SOCHPFL12AF72A3F64', count=2, user_indexed=5.0, song_indexed=767.0)\"\n",
    "assert test2 == correct2, \"the row was expected to be %s but it was %s\" % (correct2, test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "727dd4c7be717dba63b92db9019078ba",
     "grade": false,
     "grade_id": "cell-0977a9a9cc40b034",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## To Rating\n",
    "\n",
    "create RDD of Rating classes. Note that you need to use  \n",
    "http://spark.apache.org/docs/latest/api/python/reference/api/pyspark.mllib.recommendation.Rating.html#pyspark.mllib.recommendation.Rating\n",
    "\n",
    "The params of the Rating function should be user=`user_indexed`, product=`song_indexed`and rating=`count`\n",
    "\n",
    "param `df` Dataframe which has `user_indexed` and `song_indexed` fields (output from `convert()` method)  \n",
    "`return` RDD containg Rating objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57670dd79bb43ecfdd1692838499978b",
     "grade": false,
     "grade_id": "cell-e8a053d3f433c1c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def toRating(df):\n",
    "    rdd = df.rdd.map(lambda row: Rating(user=row[3],product=row[4],rating=row[2]))\n",
    "    return rdd\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71a3308c7e172345b2b4105823b25621",
     "grade": false,
     "grade_id": "cell-dee1106237c8e6ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=162, product=577, rating=2.0),\n",
       " Rating(user=162, product=1053, rating=1.0),\n",
       " Rating(user=162, product=1646, rating=1.0),\n",
       " Rating(user=162, product=1945, rating=1.0),\n",
       " Rating(user=162, product=2306, rating=1.0),\n",
       " Rating(user=162, product=2702, rating=1.0),\n",
       " Rating(user=162, product=3124, rating=1.0),\n",
       " Rating(user=810, product=951, rating=2.0),\n",
       " Rating(user=810, product=1728, rating=2.0),\n",
       " Rating(user=1151, product=3824, rating=1.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rated = toRating(converted).persist()\n",
    "rated.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c216026cac60eff1848f63962500d28",
     "grade": true,
     "grade_id": "cell-ac722ba8c4f165d9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''toRating tests'''\n",
    "rows = [Rating(user=162, product=577, rating=2.0),\n",
    " Rating(user=162, product=1053, rating=1.0),\n",
    " Rating(user=162, product=1646, rating=1.0),\n",
    " Rating(user=162, product=1945, rating=1.0),\n",
    " Rating(user=162, product=2306, rating=1.0)]\n",
    "assert rated.take(5) == rows, \"the first 5 rows were expected to be %s but they were %s\" % (rows, rated.take(5))\n",
    "\n",
    "random.seed(54321)\n",
    "r = random.randint(100, 2000)\n",
    "\n",
    "test3 = str(toRating(converted).collect()[r])\n",
    "correct3 = \"Rating(user=599, product=1321, rating=1.0)\"\n",
    "assert test3 == correct3, \"the row was expected to be %s but it was %s\" % (correct3, test3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef1dac23dcc7e0aa10c54dedb3989ee9",
     "grade": false,
     "grade_id": "cell-d457633d3a0d92bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Train ALS\n",
    "\n",
    "train ALS model. For testing purposes you have to include a seed, e.g seed=seed. Use the parameter rank=10.\n",
    "\n",
    "https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html#collaborative-filtering\n",
    "\n",
    "param `data` RDD of Rating objects that is created using `toRating()` method.  \n",
    "param `seed` value used for testing purposes. \n",
    "`return` trained ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "726819539c65d3639dfac9aa04410464",
     "grade": false,
     "grade_id": "cell-e3037a84b03f5984",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def trainALS(data, seed):\n",
    "    rank = 10\n",
    "    model = ALS.train(data, rank, seed=seed)\n",
    "    return model\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2bf7cd4f28690dc5afa0076efe6f9cd",
     "grade": false,
     "grade_id": "cell-c89fd7f76f49c8fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "rSeed = random.randint(0, 10000)\n",
    "model = trainALS(rated, rSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "252038129d3c0afdaeb2b5184a8f11f5",
     "grade": false,
     "grade_id": "cell-40bcee83d27c98bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Recommend Songs\n",
    "\n",
    "Recommend 5 most suitable songs to a given user, as in 5 songs with the highest ratings.\n",
    "\n",
    "param `model` trained ALS model  \n",
    "param `user` user id converted (user_indexed) to Integer (with `convert()`)  \n",
    "`return` recommendations in Array  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03552dc1520cabb16977c8bde4515c7a",
     "grade": false,
     "grade_id": "cell-6cacd5cd4f310748",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def recommendSongs(model, user):\n",
    "    top5 = model.recommendProducts(user,5)\n",
    "    return top5\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47d8fc0c4d3a25caa7e277872f980a21",
     "grade": false,
     "grade_id": "cell-03001d980205465e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=162, product=157, rating=12.384455745744464),\n",
       " Rating(user=162, product=4074, rating=12.091127878041066),\n",
       " Rating(user=162, product=2310, rating=12.091127878041066),\n",
       " Rating(user=162, product=3986, rating=11.486571886780661),\n",
       " Rating(user=162, product=1669, rating=11.480036775598396)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommends = recommendSongs(model, 162)\n",
    "recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d0d5f196580126f6d9742c0dfe05cb6",
     "grade": true,
     "grade_id": "cell-7400cddbdaf2d604",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''model and recommendSongs tests'''\n",
    "assert type(recommends[0]) == pyspark.mllib.recommendation.Rating, \"the type was expected to be pyspark.mllib.recommendation.Rating  but it was %s\" % type(recommends[0]) \n",
    "assert recommends[0].user == 162, \"the user was expected to be 162 but it was %s\" % recommends[0].user\n",
    "assert len(recommends) == 5, \"the amount of recommendations was expected to be 5 but it was %s\" % len(recommends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fff44e27e9b66ba9909d64a535ff80c5",
     "grade": false,
     "grade_id": "cell-f0413da1c50b0651",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Get Song Names\n",
    "\n",
    "Get the song name and the artist for a given Rating object\n",
    "\n",
    "Example\n",
    "\n",
    "`[Rating(182412,218057,29.471691093542958),  \n",
    "Rating(182412,206693,28.39630617887081),  \n",
    "Rating(182412,230654,28.090021579109706),  \n",
    "Rating(182412,200542,27.43900484648816),  \n",
    "Rating(182412,254771,24.82362529344695)] ` \n",
    "\n",
    "You should create something like this  \n",
    "\n",
    "`[[\"My Business\",\"Guy\"],  \n",
    "[\"The Man With The Bag\",\"Floyd/Animal/Zoot\"],  \n",
    "[\"Challenger\",\"Growing\"],  \n",
    "[\"Una Ragazza In Due\", \"I Giganti\"],\n",
    "[\"That Is Why\", \"Say Anything\"]]`  \n",
    "\n",
    "First the song name and then the name of the band\n",
    "\n",
    "You should start by converting the unique_tracks data into a dataframe. Columns are seperated by `<SEP>`. The correct schema is:\n",
    "\n",
    "-> `track_id`: String  \n",
    "-> `song_id`: String  \n",
    "-> `artist`: String  \n",
    "-> `title`: String\n",
    "\n",
    "Next you should filter the `converted` dataframe based on if the `song_indexed` value is found in the Rating object array. Then you should Join the two dataframes and select the \"title\" and \"artist\" values. You will want to exclude duplicates. Finally, convert the dataframe into array (e.g convert it to rdd and use the collect() method).\n",
    "\n",
    "\n",
    "param `converted` Dataframe created using `convert()` method  \n",
    "param `ar` Array of Rating object produced using `recommendSongs()`  \n",
    "param `path` path to unique track names file  \n",
    "`return` corresponding song + artist names inside array, e.g., [['Our Song', 'Taylor Swift'],\n",
    " ['Boom (2006 Remastered Album Version)', 'P.O.D.']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1132d43fcde2c22c8ffca020e90ff56",
     "grade": false,
     "grade_id": "cell-9f0fbcc5642a52fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def getSongNames(converted, ar, path):\n",
    "    schema = StructType([\n",
    "                        StructField(\"track_id\", StringType()), \n",
    "                        StructField(\"song_id\", StringType()),\n",
    "                        StructField(\"artist\", StringType()),\n",
    "                        StructField(\"title\", StringType())\n",
    "    ])\n",
    "    \n",
    "    tracks = spark.read.text(path)\n",
    "    tracksRDD = tracks.rdd.map(lambda row: row.value.split('<SEP>'))\n",
    "    arr = []\n",
    "    for each in ar:\n",
    "        arr.append(each[1])\n",
    "    songs = converted.rdd.filter(lambda song: song[4] in arr).toDF()\n",
    "    tracksDF = spark.createDataFrame(tracksRDD, schema)\n",
    "    joinedSong = tracksDF.join(songs, tracksDF[\"song_id\"] == songs[\"song\"], how=\"inner\")\n",
    "    joinedSong = joinedSong.select(\"title\", \"artist\").distinct()\n",
    "    rec_song = joinedSong.rdd.map(lambda row: [row[0], row[1]]).collect()\n",
    "    return rec_song\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "789886c9de59c410f741a1d86f9c4204",
     "grade": false,
     "grade_id": "cell-2764ba1c6b246edd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cordeiro De Nana', 'João Gilberto / Gilberto Gil / Caetano Veloso'],\n",
       " ['Limbo (Remastered LP Version)', 'Rush'],\n",
       " ['Whataya Want From Me', 'Adam Lambert'],\n",
       " ['Awakenings', 'Symphony X'],\n",
       " ['Inferno (unleash The Fire)', 'Symphony X']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songNames = getSongNames(converted, recommends, sampleTracksPath)\n",
    "songNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "672c7eff730610e5fe5e2e83e1895539",
     "grade": true,
     "grade_id": "cell-200f887e9e5a7de7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''getSongNames test'''\n",
    "assert len(songNames) == 5, \"the amount of song names was expected to be 5 but it was %s\" % len(songNames)\n",
    "assert type(songNames[0]) == list, \"the type of a songNames element was expected to be list but it was %s\" % type(songNames[0])\n",
    "test5 = songNames[3]\n",
    "correct5 = ['Awakenings', 'Symphony X']\n",
    "assert test5 == correct5, \"the row was expected to be %s but it was %s\" % (correct5, test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8dd7f2c94ae333017a6c55974bd6780",
     "grade": false,
     "grade_id": "cell-0a7cb1405f9415a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Recommend\n",
    "\n",
    "Recommend returns 5 song recommendations for a given user_id. Output should consists of Arrays that are size of 2. First element of the array is song name and the second artist name. You will basically just have to insert the parameters into the methods you have created. Remember the type of parameter that `recommendSongs()` accepts.\n",
    "\n",
    "Example return\n",
    "\n",
    "`[[\"My Business\",\"Guy\"],  \n",
    "[\"The Man With The Bag\",\"Floyd/Animal/Zoot\"],  \n",
    "[\"Challenger\",\"Growing\"],  \n",
    "[\"Una Ragazza In Due\", \"I Giganti\"],\n",
    "[\"That Is Why\", \"Say Anything\"]]`   \n",
    "\n",
    "param `path` path to user data  \n",
    "param `userId` user_id (String) that can be found from user dataset  \n",
    "param `tracksPath` path to unique song names dataset   \n",
    "param `seed` used for testing, put it into the `trainsALS()` method   \n",
    "`return` corresponding song + artist names inside array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eef84895ced1de0d80dd701afd72fc21",
     "grade": false,
     "grade_id": "cell-4a4f363fd2d7df22",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def recommend(path, userId, tracksPath, seed):\n",
    "    userDF = load(path)\n",
    "    convDF = convert(userDF)\n",
    "    toRateRDD = toRating(convDF)\n",
    "    model = trainALS(toRateRDD, seed)\n",
    "    user = convDF.where(convDF[\"user\"]==userId)\n",
    "    user = user.first().user_indexed\n",
    "    recos = recommendSongs(model, int(user))\n",
    "    rec_songs = getSongNames(convDF, recos, tracksPath)\n",
    "    return rec_songs\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "612f49d0168f9661a1324be0c7772d17",
     "grade": false,
     "grade_id": "cell-88500d4d410e7a67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cordeiro De Nana', 'João Gilberto / Gilberto Gil / Caetano Veloso'],\n",
       " ['Limbo (Remastered LP Version)', 'Rush'],\n",
       " ['Whataya Want From Me', 'Adam Lambert'],\n",
       " ['Awakenings', 'Symphony X'],\n",
       " ['Inferno (unleash The Fire)', 'Symphony X']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom = recommend(sampleUsersPath, \"b80344d063b5ccb3212f76538f3d9e43d87dca9e\" ,sampleTracksPath, rSeed)\n",
    "recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ba43bb74229798589f41d1a20146b62",
     "grade": true,
     "grade_id": "cell-0d940ea5134022c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''recommend test'''\n",
    "assert len(recom) == 5, \"the amount of recommendations was expected to be 5 but it was %s\" % len(recom)\n",
    "assert type(recom[0]) == list, \"the type of a 'recommend' element was expected to be list but it was %s\" % type(recom[0])\n",
    "#test if the same user and seed returns the same as songNames\n",
    "assert recom == songNames, \"the song names were expected to be %s but they were %s\" % (songNames, recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd90d19ebc7be3ec30cc7c063c8ca754",
     "grade": false,
     "grade_id": "cell-85e292901a3f8834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "sc.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d074b6b7a4d7b8adf89df935b7701a8c4e0af999254745575407f19f2a6d6544"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
